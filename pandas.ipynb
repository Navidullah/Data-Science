{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\">Pandas in Python</h1>\n",
    "<p style=\"font-size:18px;\">Pandas is a powerful and popular data manipulation and analysis library in Python. It provides data structures like Series and DataFrame that are well-suited for working with structured data, such as spreadsheets or SQL tables. Pandas makes it easy to clean, analyze, and visualize data, making it a fundamental tool for data scientists, analysts, and engineers. Here's an overview of how to use Pandas in Python:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Inspecting a Dataframe</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you get a new DataFrame to work with, the first thing you need to do is explore it and see what it contains. There are several useful methods and attributes for this.\n",
    "\n",
    "<li>.head() returns the first few rows (the “head” of the DataFrame).</li>\n",
    "<li>.info() shows information on each of the columns, such as the data type and number of missing values.</li>\n",
    "<li>.shape returns the number of rows and columns of the DataFrame.</li>\n",
    "<li>.describe() calculates a few summary statistics for each column.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region       state  individuals  family_members  state_pop\n",
       "0  East South Central     Alabama       2570.0           864.0    4887681\n",
       "1             Pacific      Alaska       1434.0           582.0     735139\n",
       "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
       "3  West South Central    Arkansas       2280.0           432.0    3009733\n",
       "4             Pacific  California     109008.0         20964.0   39461588"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import the cars.csv data: cars\n",
    "home_data = pd.read_csv('C:/Users/RBTG/OneDrive/Desktop/Data science/data/home_data.csv')\n",
    "\n",
    "home_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   region          51 non-null     object \n",
      " 1   state           51 non-null     object \n",
      " 2   individuals     51 non-null     float64\n",
      " 3   family_members  51 non-null     float64\n",
      " 4   state_pop       51 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "home_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7225.784314</td>\n",
       "      <td>3504.882353</td>\n",
       "      <td>6.405637e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15991.025083</td>\n",
       "      <td>7805.411811</td>\n",
       "      <td>7.327258e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>434.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>5.776010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1446.500000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>1.777414e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3082.000000</td>\n",
       "      <td>1482.000000</td>\n",
       "      <td>4.461153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6781.500000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>7.340946e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109008.000000</td>\n",
       "      <td>52070.000000</td>\n",
       "      <td>3.946159e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         individuals  family_members     state_pop\n",
       "count      51.000000       51.000000  5.100000e+01\n",
       "mean     7225.784314     3504.882353  6.405637e+06\n",
       "std     15991.025083     7805.411811  7.327258e+06\n",
       "min       434.000000       75.000000  5.776010e+05\n",
       "25%      1446.500000      592.000000  1.777414e+06\n",
       "50%      3082.000000     1482.000000  4.461153e+06\n",
       "75%      6781.500000     3196.000000  7.340946e+06\n",
       "max    109008.000000    52070.000000  3.946159e+07"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Parts of a DataFrame</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand DataFrame objects, it's useful to know that they consist of three components, stored as attributes:\n",
    "\n",
    "<li>.values: A two-dimensional NumPy array of values.</li>\n",
    "<li>.columns: An index of columns: the column names.</li>\n",
    "<li>.index: An index for the rows: either row numbers or row names.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Print a 2D NumPy array of the values in homelessness.</li>\n",
    "<li>Print the column names of homelessness.</li>\n",
    "<li>Print the index of homelessness.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n",
      " ['Pacific' 'Alaska' 1434.0 582.0 735139]\n",
      " ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n",
      " ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n",
      " ['Pacific' 'California' 109008.0 20964.0 39461588]\n",
      " ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n",
      " ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n",
      " ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n",
      " ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n",
      " ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n",
      " ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n",
      " ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n",
      " ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n",
      " ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n",
      " ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n",
      " ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n",
      " ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n",
      " ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n",
      " ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n",
      " ['New England' 'Maine' 1450.0 1066.0 1339057]\n",
      " ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n",
      " ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n",
      " ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n",
      " ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n",
      " ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n",
      " ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n",
      " ['Mountain' 'Montana' 983.0 422.0 1060665]\n",
      " ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n",
      " ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n",
      " ['New England' 'New Hampshire' 835.0 615.0 1353465]\n",
      " ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n",
      " ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n",
      " ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n",
      " ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n",
      " ['West North Central' 'North Dakota' 467.0 75.0 758080]\n",
      " ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n",
      " ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n",
      " ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n",
      " ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n",
      " ['New England' 'Rhode Island' 747.0 354.0 1058287]\n",
      " ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n",
      " ['West North Central' 'South Dakota' 836.0 323.0 878698]\n",
      " ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n",
      " ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n",
      " ['Mountain' 'Utah' 1904.0 972.0 3153550]\n",
      " ['New England' 'Vermont' 780.0 511.0 624358]\n",
      " ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n",
      " ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n",
      " ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n",
      " ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n",
      " ['Mountain' 'Wyoming' 434.0 205.0 577601]]\n",
      "Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n",
      "RangeIndex(start=0, stop=51, step=1)\n"
     ]
    }
   ],
   "source": [
    "# Print the values of homelessness\n",
    "print(home_data.values)\n",
    "\n",
    "# Print the column index of homelessness\n",
    "print(home_data.columns)\n",
    "\n",
    "# Print the row index of homelessness\n",
    "print(home_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Sorting rows</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding interesting bits of data in a DataFrame is often easier if you change the order of the rows. You can sort the rows by passing a column name to .sort_values().<br>\n",
    "\n",
    "In cases where rows have the same value (this is common if you sort on a categorical variable), you may wish to break the ties by sorting on another column. You can sort on multiple columns in this way by passing a list of column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgreen;\">Sort homelessness by the number of homeless individuals in the individuals column, from smallest to largest, and save this as home_data_ind.\n",
    "Print the head of the sorted DataFrame.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>434.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>467.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>758080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>708.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>965479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>New England</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>747.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1058287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>New England</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>780.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>624358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region         state  individuals  family_members  state_pop\n",
       "50            Mountain       Wyoming        434.0           205.0     577601\n",
       "34  West North Central  North Dakota        467.0            75.0     758080\n",
       "7       South Atlantic      Delaware        708.0           374.0     965479\n",
       "39         New England  Rhode Island        747.0           354.0    1058287\n",
       "45         New England       Vermont        780.0           511.0     624358"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort homelessness by individuals\n",
    "home_data_ind = home_data.sort_values('individuals')\n",
    "\n",
    "# Print the top few rows\n",
    "home_data_ind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgreen;\">Sort homelessness by the number of homeless family_members in descending order, and save this as home_data_fam.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New York</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>19530351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New England</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6811.0</td>\n",
       "      <td>13257.0</td>\n",
       "      <td>6882635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>21244317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19199.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>28628666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region          state  individuals  family_members  state_pop\n",
       "32        Mid-Atlantic       New York      39827.0         52070.0   19530351\n",
       "4              Pacific     California     109008.0         20964.0   39461588\n",
       "21         New England  Massachusetts       6811.0         13257.0    6882635\n",
       "9       South Atlantic        Florida      21443.0          9587.0   21244317\n",
       "43  West South Central          Texas      19199.0          6111.0   28628666"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort homelessness by individuals\n",
    "home_data_fam = home_data.sort_values('family_members', ascending=False)\n",
    "\n",
    "# Print the top few rows\n",
    "home_data_fam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgreen;\">Sort homelessness first by region (ascending), and then by number of family members (descending). Save this as home_data_reg_fam.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>3891.0</td>\n",
       "      <td>12723071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>6929.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>11676341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>5209.0</td>\n",
       "      <td>3142.0</td>\n",
       "      <td>9984072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>5807406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>3776.0</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>6695497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region      state  individuals  family_members  state_pop\n",
       "13  East North Central   Illinois       6752.0          3891.0   12723071\n",
       "35  East North Central       Ohio       6929.0          3320.0   11676341\n",
       "22  East North Central   Michigan       5209.0          3142.0    9984072\n",
       "49  East North Central  Wisconsin       2740.0          2167.0    5807406\n",
       "14  East North Central    Indiana       3776.0          1482.0    6695497"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort homelessness by region, then descending family members\n",
    "home_data_reg_fam = home_data.sort_values(['region','family_members'],ascending=[True,False])\n",
    "\n",
    "# Print the top few rows\n",
    "home_data_reg_fam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Subsetting the Columns</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with data, you may not need all of the variables in your dataset. Square brackets ([]) can be used to select only the columns that matter to you in an order that makes sense to you. To select only specific column of the DataFrame df,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgreen;\">Create a Series called individuals that contains only the individuals column of home_data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2570.0\n",
      "1      1434.0\n",
      "2      7259.0\n",
      "3      2280.0\n",
      "4    109008.0\n",
      "Name: individuals, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "individuals = home_data['individuals']\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Subsetting rows</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large part of data science is about finding which bits of your dataset are interesting. One of the simplest techniques for this is to find a subset of rows that match some criteria. This is sometimes known as filtering rows or selecting rows.\n",
    "\n",
    "\n",
    "<span style=\"color:lightgreen;\">Filter home_data for cases where the number of individuals is greater than ten thousand, assigning to ind_gt_10k. View the printed result.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region       state  individuals  family_members  state_pop\n",
      "4              Pacific  California     109008.0         20964.0   39461588\n",
      "9       South Atlantic     Florida      21443.0          9587.0   21244317\n",
      "32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n",
      "37             Pacific      Oregon      11139.0          3337.0    4181886\n",
      "43  West South Central       Texas      19199.0          6111.0   28628666\n",
      "47             Pacific  Washington      16424.0          5880.0    7523869\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = home_data[home_data['individuals']>10000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgreen;\">Filter homelessness for cases where the USA Census region is \"Mountain\", assigning to mountain_reg. View the printed result.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "5   Mountain    Colorado       7607.0          3250.0    5691287\n",
      "12  Mountain       Idaho       1297.0           715.0    1750536\n",
      "26  Mountain     Montana        983.0           422.0    1060665\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "31  Mountain  New Mexico       1949.0           602.0    2092741\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n",
      "50  Mountain     Wyoming        434.0           205.0     577601\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = home_data[home_data['region']=='Mountain']\n",
    "\n",
    "# See the result\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span style=\"color:lightgreen;\">Filter for rows where family_members is less than 1000 and region is Pacific</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region   state  individuals  family_members  state_pop\n",
      "1  Pacific  Alaska       1434.0           582.0     735139\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where family_members is less than 1000 \n",
    "# and region is Pacific\n",
    "fam_lt_1k_pac = home_data[(home_data['region']=='Pacific') & (home_data['family_members'] <1000)]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgreen;\">Subsetting rows by categorical variables</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetting data based on a categorical variable often involves using the \"or\" operator (|) to select rows from multiple categories. This can get tedious when you want all states in one of three different regions, for example. Instead, use the .isin() method, which will allow you to tackle this problem by writing one condition instead of three separate ones.<br>\n",
    "\n",
    "colors = [\"brown\", \"black\", \"tan\"]<br>\n",
    "condition = dogs[\"color\"].isin(colors)<br>\n",
    "dogs[condition]\n",
    "\n",
    "<span style=\"color:lightgreen;\">Filter home_data for cases where the USA census state is in the list of Mojave states, canu, assigning to mojave_home_data. View the printed result.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "4    Pacific  California     109008.0         20964.0   39461588\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n"
     ]
    }
   ],
   "source": [
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_home_data = home_data[home_data['state'].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "print(mojave_home_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Adding new Columns</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You aren't stuck with just the data you are given. Instead, you can add new columns to a DataFrame. This has many names, such as transforming, mutating, and feature engineering.<br>\n",
    "\n",
    "You can create new columns from scratch, but it is also common to derive them from other columns, for example, by adding columns together or by changing their units.<br>\n",
    "\n",
    "home_data is a DataFrame containing estimates of home_data in each U.S. state in 2018. The individual column is the number of homeless individuals not part of a family with children. The family_members column is the number of homeless individuals part of a family with children. The state_pop column is the state's total population.<br>\n",
    "\n",
    "home_data is available and pandas is loaded as pd.<br>\n",
    "\n",
    "<li style='color:lightGreen;'>Add a new column to home_data, named total, containing the sum of the individuals and family_members columns.</li>\n",
    "<li style='color:lightGreen;'>Add another column to home_data, named p_homeless, containing the proportion of the total homeless population to the total population in each state state_pop.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "      <th>total</th>\n",
       "      <th>p_homeless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "      <td>3434.0</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "      <td>9865.0</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "      <td>129972.0</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>7607.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>5691287</td>\n",
       "      <td>10857.0</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New England</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>3571520</td>\n",
       "      <td>3976.0</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>708.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>965479</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>0.001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>701547</td>\n",
       "      <td>6904.0</td>\n",
       "      <td>0.009841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>21244317</td>\n",
       "      <td>31030.0</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>10511131</td>\n",
       "      <td>9499.0</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>4131.0</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>1420593</td>\n",
       "      <td>6530.0</td>\n",
       "      <td>0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1750536</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>3891.0</td>\n",
       "      <td>12723071</td>\n",
       "      <td>10643.0</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>3776.0</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>6695497</td>\n",
       "      <td>5258.0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>3148618</td>\n",
       "      <td>2749.0</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>2911359</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2735.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>4461153</td>\n",
       "      <td>3688.0</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>4659690</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>0.000656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New England</td>\n",
       "      <td>Maine</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>1339057</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>6035802</td>\n",
       "      <td>7144.0</td>\n",
       "      <td>0.001184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New England</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6811.0</td>\n",
       "      <td>13257.0</td>\n",
       "      <td>6882635</td>\n",
       "      <td>20068.0</td>\n",
       "      <td>0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>5209.0</td>\n",
       "      <td>3142.0</td>\n",
       "      <td>9984072</td>\n",
       "      <td>8351.0</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>3993.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>5606249</td>\n",
       "      <td>7243.0</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2981020</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>3776.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>6121623</td>\n",
       "      <td>5883.0</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Montana</td>\n",
       "      <td>983.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1060665</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1925614</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>7058.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>3027341</td>\n",
       "      <td>7544.0</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New England</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>835.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1353465</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>6048.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>8886025</td>\n",
       "      <td>9398.0</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>2092741</td>\n",
       "      <td>2551.0</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New York</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>19530351</td>\n",
       "      <td>91897.0</td>\n",
       "      <td>0.004705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>6451.0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>10381615</td>\n",
       "      <td>9268.0</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>467.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>758080</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>6929.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>11676341</td>\n",
       "      <td>10249.0</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>3940235</td>\n",
       "      <td>3871.0</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>11139.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>4181886</td>\n",
       "      <td>14476.0</td>\n",
       "      <td>0.003462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>8163.0</td>\n",
       "      <td>5349.0</td>\n",
       "      <td>12800922</td>\n",
       "      <td>13512.0</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>New England</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>747.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1058287</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>3082.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>5084156</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>836.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>878698</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>0.001319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>6139.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>6771631</td>\n",
       "      <td>7883.0</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19199.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>28628666</td>\n",
       "      <td>25310.0</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Utah</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>3153550</td>\n",
       "      <td>2876.0</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>New England</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>780.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>624358</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>0.002068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>3928.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>8501286</td>\n",
       "      <td>5975.0</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Washington</td>\n",
       "      <td>16424.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>7523869</td>\n",
       "      <td>22304.0</td>\n",
       "      <td>0.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1804291</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>5807406</td>\n",
       "      <td>4907.0</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>434.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577601</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region                 state  individuals  family_members  \\\n",
       "0   East South Central               Alabama       2570.0           864.0   \n",
       "1              Pacific                Alaska       1434.0           582.0   \n",
       "2             Mountain               Arizona       7259.0          2606.0   \n",
       "3   West South Central              Arkansas       2280.0           432.0   \n",
       "4              Pacific            California     109008.0         20964.0   \n",
       "5             Mountain              Colorado       7607.0          3250.0   \n",
       "6          New England           Connecticut       2280.0          1696.0   \n",
       "7       South Atlantic              Delaware        708.0           374.0   \n",
       "8       South Atlantic  District of Columbia       3770.0          3134.0   \n",
       "9       South Atlantic               Florida      21443.0          9587.0   \n",
       "10      South Atlantic               Georgia       6943.0          2556.0   \n",
       "11             Pacific                Hawaii       4131.0          2399.0   \n",
       "12            Mountain                 Idaho       1297.0           715.0   \n",
       "13  East North Central              Illinois       6752.0          3891.0   \n",
       "14  East North Central               Indiana       3776.0          1482.0   \n",
       "15  West North Central                  Iowa       1711.0          1038.0   \n",
       "16  West North Central                Kansas       1443.0           773.0   \n",
       "17  East South Central              Kentucky       2735.0           953.0   \n",
       "18  West South Central             Louisiana       2540.0           519.0   \n",
       "19         New England                 Maine       1450.0          1066.0   \n",
       "20      South Atlantic              Maryland       4914.0          2230.0   \n",
       "21         New England         Massachusetts       6811.0         13257.0   \n",
       "22  East North Central              Michigan       5209.0          3142.0   \n",
       "23  West North Central             Minnesota       3993.0          3250.0   \n",
       "24  East South Central           Mississippi       1024.0           328.0   \n",
       "25  West North Central              Missouri       3776.0          2107.0   \n",
       "26            Mountain               Montana        983.0           422.0   \n",
       "27  West North Central              Nebraska       1745.0           676.0   \n",
       "28            Mountain                Nevada       7058.0           486.0   \n",
       "29         New England         New Hampshire        835.0           615.0   \n",
       "30        Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
       "31            Mountain            New Mexico       1949.0           602.0   \n",
       "32        Mid-Atlantic              New York      39827.0         52070.0   \n",
       "33      South Atlantic        North Carolina       6451.0          2817.0   \n",
       "34  West North Central          North Dakota        467.0            75.0   \n",
       "35  East North Central                  Ohio       6929.0          3320.0   \n",
       "36  West South Central              Oklahoma       2823.0          1048.0   \n",
       "37             Pacific                Oregon      11139.0          3337.0   \n",
       "38        Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
       "39         New England          Rhode Island        747.0           354.0   \n",
       "40      South Atlantic        South Carolina       3082.0           851.0   \n",
       "41  West North Central          South Dakota        836.0           323.0   \n",
       "42  East South Central             Tennessee       6139.0          1744.0   \n",
       "43  West South Central                 Texas      19199.0          6111.0   \n",
       "44            Mountain                  Utah       1904.0           972.0   \n",
       "45         New England               Vermont        780.0           511.0   \n",
       "46      South Atlantic              Virginia       3928.0          2047.0   \n",
       "47             Pacific            Washington      16424.0          5880.0   \n",
       "48      South Atlantic         West Virginia       1021.0           222.0   \n",
       "49  East North Central             Wisconsin       2740.0          2167.0   \n",
       "50            Mountain               Wyoming        434.0           205.0   \n",
       "\n",
       "    state_pop     total  p_homeless  \n",
       "0     4887681    3434.0    0.000703  \n",
       "1      735139    2016.0    0.002742  \n",
       "2     7158024    9865.0    0.001378  \n",
       "3     3009733    2712.0    0.000901  \n",
       "4    39461588  129972.0    0.003294  \n",
       "5     5691287   10857.0    0.001908  \n",
       "6     3571520    3976.0    0.001113  \n",
       "7      965479    1082.0    0.001121  \n",
       "8      701547    6904.0    0.009841  \n",
       "9    21244317   31030.0    0.001461  \n",
       "10   10511131    9499.0    0.000904  \n",
       "11    1420593    6530.0    0.004597  \n",
       "12    1750536    2012.0    0.001149  \n",
       "13   12723071   10643.0    0.000837  \n",
       "14    6695497    5258.0    0.000785  \n",
       "15    3148618    2749.0    0.000873  \n",
       "16    2911359    2216.0    0.000761  \n",
       "17    4461153    3688.0    0.000827  \n",
       "18    4659690    3059.0    0.000656  \n",
       "19    1339057    2516.0    0.001879  \n",
       "20    6035802    7144.0    0.001184  \n",
       "21    6882635   20068.0    0.002916  \n",
       "22    9984072    8351.0    0.000836  \n",
       "23    5606249    7243.0    0.001292  \n",
       "24    2981020    1352.0    0.000454  \n",
       "25    6121623    5883.0    0.000961  \n",
       "26    1060665    1405.0    0.001325  \n",
       "27    1925614    2421.0    0.001257  \n",
       "28    3027341    7544.0    0.002492  \n",
       "29    1353465    1450.0    0.001071  \n",
       "30    8886025    9398.0    0.001058  \n",
       "31    2092741    2551.0    0.001219  \n",
       "32   19530351   91897.0    0.004705  \n",
       "33   10381615    9268.0    0.000893  \n",
       "34     758080     542.0    0.000715  \n",
       "35   11676341   10249.0    0.000878  \n",
       "36    3940235    3871.0    0.000982  \n",
       "37    4181886   14476.0    0.003462  \n",
       "38   12800922   13512.0    0.001056  \n",
       "39    1058287    1101.0    0.001040  \n",
       "40    5084156    3933.0    0.000774  \n",
       "41     878698    1159.0    0.001319  \n",
       "42    6771631    7883.0    0.001164  \n",
       "43   28628666   25310.0    0.000884  \n",
       "44    3153550    2876.0    0.000912  \n",
       "45     624358    1291.0    0.002068  \n",
       "46    8501286    5975.0    0.000703  \n",
       "47    7523869   22304.0    0.002964  \n",
       "48    1804291    1243.0    0.000689  \n",
       "49    5807406    4907.0    0.000845  \n",
       "50     577601     639.0    0.001106  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "home_data[\"total\"]=home_data['individuals']+home_data['family_members']\n",
    "\n",
    "# Add p_homeless col as proportion of total homeless population to the state population\n",
    "home_data['p_homeless']=home_data['total'] / home_data['state_pop']\n",
    "\n",
    "# See the result\n",
    "home_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've seen the four most common types of data manipulation: sorting rows, subsetting columns, subsetting rows, and adding new columns. In a real-life data analysis, you can mix and match these four manipulations to answer a multitude of questions.<br>\n",
    "\n",
    "In this exercise, you'll answer the question, \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" Combine your new pandas skills to find out.<br>\n",
    "\n",
    "<li style='color:lightGreen;'>Add a column to homelessness, indiv_per_10k, containing the number of homeless individuals per ten thousand people in each state, using state_pop for state population.</li>\n",
    "<li style='color:lightGreen;'>Subset rows where indiv_per_10k is higher than 20, assigning to high_homelessness.</li>\n",
    "<li style='color:lightGreen;'>Sort high_homelessness by descending indiv_per_10k, assigning to high_homelessness_srt.</li>\n",
    "<li style='color:lightGreen;'>Select only the state and indiv_per_10k columns of high_homelessness_srt and save as result. Look at the result.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   state  indiv_per_10k\n",
      "8   District of Columbia      53.738381\n",
      "11                Hawaii      29.079406\n",
      "4             California      27.623825\n",
      "37                Oregon      26.636307\n",
      "28                Nevada      23.314189\n",
      "47            Washington      21.829195\n",
      "32              New York      20.392363\n"
     ]
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "home_data[\"indiv_per_10k\"] = 10000 * home_data['individuals'] /home_data['state_pop'] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = home_data[home_data['indiv_per_10k'] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt =high_homelessness.sort_values('indiv_per_10k',ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "#result = high_homelessness_srt.loc[:,['state','indiv_per_10k']]\n",
    "result = high_homelessness_srt[['state','indiv_per_10k']]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool combination! District of Columbia has the highest number of homeless individuals - almost 54 per ten thousand people. This is almost double the number of the next-highest state, Hawaii. If you combine new column addition, row subsetting, sorting, and column selection, you can answer lots of questions like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Dictionary to DataFrame</h3>\n",
    "<p style=\"font-size:18px;\">Pandas is an open source library, providing high-performance, easy-to-use data structures and data analysis tools for Python. Sounds promising!\n",
    "\n",
    "The DataFrame is one of Pandas' most important data structures. It's basically a way to store tabular data where you can label the rows and the columns. One way to build a DataFrame is from a dictionary.\n",
    "\n",
    "In the exercises that follow you will be working with vehicle data from different countries. Each observation corresponds to a country and the columns give information about the number of vehicles per capita, whether people drive left or right, and so on.</p>\n",
    "\n",
    "<li>names, containing the country names for which data is available.</li>\n",
    "<li>dr, a list with booleans that tells whether people drive left or right in the corresponding country.</li>\n",
    "<li>cpc, the number of motor vehicles per 1000 people in the corresponding country.</li>\n",
    "\n",
    "<p>Each dictionary key is a column label and each value is a list which contains the column elements.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Import pandas as pd.</li>\n",
    "<li>Use the pre-defined lists to create a dictionary called my_dict. There should be three key value pairs:</li>\n",
    "<li>key 'country' and value names.</li>\n",
    "<li>key 'drives_right' and value dr.</li>\n",
    "<li>key 'cars_per_cap' and value cpc.</li>\n",
    "<li>Use pd.DataFrame() to turn your dict into a DataFrame called cars.</li>\n",
    "<li>Print out cars and see how beautiful it is.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         country  drives_right  cars_per_cap\n",
      "0  United States          True           809\n",
      "1      Australia         False           731\n",
      "2          Japan         False           588\n",
      "3          India         False            18\n",
      "4         Russia          True           200\n",
      "5        Morocco          True            70\n",
      "6          Egypt          True            45\n"
     ]
    }
   ],
   "source": [
    "# Pre-defined lists\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
    "\n",
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create dictionary my_dict with three key:value pairs: my_dict\n",
    "my_dict ={\n",
    "    'country': names,\n",
    "    'drives_right':dr,\n",
    "    'cars_per_cap':cpc\n",
    "}\n",
    "\n",
    "\n",
    "# Build a DataFrame cars from my_dict: cars\n",
    "cars = pd.DataFrame(my_dict)\n",
    "\n",
    "\n",
    "# Print cars\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The Python code that solves the previous exercise is included in the script. Have you noticed that the row labels (i.e. the labels for the different observations) were automatically set to integers from 0 up to 6?\n",
    "\n",
    "To solve this a list row_labels has been created. You can use it to specify the row labels of the cars DataFrame. You do this by setting the index attribute of cars, that you can access as cars.index.</p>\n",
    "\n",
    "<li>Specify the row labels by setting cars.index equal to row_labels.</li>\n",
    "<li>Print out cars again and check if the row labels are correct this time.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           country  drives_right  cars_per_cap\n",
      "US   United States          True           809\n",
      "AUS      Australia         False           731\n",
      "JPN          Japan         False           588\n",
      "IN           India         False            18\n",
      "RU          Russia          True           200\n",
      "MOR        Morocco          True            70\n",
      "EG           Egypt          True            45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build cars DataFrame\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
    "cars_dict = { 'country':names, 'drives_right':dr, 'cars_per_cap':cpc }\n",
    "cars = pd.DataFrame(cars_dict)\n",
    "\n",
    "\n",
    "# Definition of row_labels\n",
    "row_labels = ['US', 'AUS', 'JPN', 'IN', 'RU', 'MOR', 'EG']\n",
    "\n",
    "# Specify row labels of cars\n",
    "cars.index =row_labels\n",
    "\n",
    "\n",
    "# Print cars again\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">CSV to DataFrame</h3>\n",
    "<p>Putting data in a dictionary and then building a DataFrame works, but it's not very efficient. What if you're dealing with millions of observations? In those cases, the data is typically available as files with a regular structure. One of those file types is the CSV file, which is short for \"comma-separated values\".\n",
    "\n",
    "To import CSV data into Python as a Pandas DataFrame you can use read_csv().\n",
    "\n",
    "Let's explore this function with the same cars data from the previous exercises. This time, however, the data is available in a CSV file, named cars.csv. It is available in your current working directory, so the path to the file is simply 'cars.csv'.\n",
    "<li>To import CSV files you still need the pandas package: import it as pd.</li>\n",
    "<li>Use pd.read_csv() to import cars.csv data as a DataFrame. Store this DataFrame as cars.</li>\n",
    "<li>Print out cars. Does everything look OK?</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0        country drives_right  cars_per_cap\n",
      "0         US  United States         True           809\n",
      "1        AUS      Australia        False           731\n",
      "2        JPN          Japan        False           588\n",
      "3         IN          India        False            18\n",
      "4         RU         Russia         True           200\n",
      "5        MOR        Morocco         True            70\n",
      "6         EG          Egypt         True            45\n"
     ]
    }
   ],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import the cars.csv data: cars\n",
    "cars = pd.read_csv('C:/Users/RBTG/OneDrive/Desktop/Data science/data/cars.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print out cars\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Your read_csv() call to import the CSV data didn't generate an error, but the output is not entirely what we wanted. The row labels were imported as another column without a name.\n",
    "\n",
    "Remember index_col, an argument of read_csv(), that you can use to specify which column in the CSV file should be used as a row label? Well, that's exactly what you need here!\n",
    "\n",
    "Python code that solves the previous exercise is already included; can you make the appropriate changes to fix the data import?\n",
    "<li>Run the code with Run Code and assert that the first column should actually be used as row labels.\n",
    "\n",
    "</li>\n",
    "<li>Specify the index_col argument inside pd.read_csv(): set it to 0, so that the first column is used as row labels.</li>\n",
    "<li>Has the printout of cars improved now?</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           country drives_right  cars_per_cap\n",
      "US   United States         True           809\n",
      "AUS      Australia        False           731\n",
      "JPN          Japan        False           588\n",
      "IN           India        False            18\n",
      "RU          Russia         True           200\n",
      "MOR        Morocco         True            70\n",
      "EG           Egypt         True            45\n"
     ]
    }
   ],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Fix import by including index_col\n",
    "cars = pd.read_csv('C:/Users/RBTG/OneDrive/Desktop/Data science/data/cars.txt',index_col = 0)\n",
    "\n",
    "# Print out cars\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Accessing DataFrames</h3>\n",
    "<h3 style=\"color:orange;\">Square Brackets Technique</h3>\n",
    "<p style=\"font-size:18px;\">In the sample code, the same cars data is imported from a CSV files as a Pandas DataFrame.<br> To select only the cars_per_cap column from cars, you can use:\n",
    "\n",
    "cars['cars_per_cap'] <br>\n",
    "cars[['cars_per_cap']] <br>\n",
    "The single bracket version gives a Pandas Series, the double bracket version gives a Pandas DataFrame.</p>\n",
    "\n",
    "<li>Use single square brackets to print out the country column of cars as a Pandas Series.</li>\n",
    "<li>Use double square brackets to print out the country column of cars as a Pandas DataFrame.</li>\n",
    "<li>Use double square brackets to print out a DataFrame with both the country and drives_right columns of cars, in this order.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US     United States\n",
      "AUS        Australia\n",
      "JPN            Japan\n",
      "IN             India\n",
      "RU            Russia\n",
      "MOR          Morocco\n",
      "EG             Egypt\n",
      "Name: country, dtype: object\n",
      "           country\n",
      "US   United States\n",
      "AUS      Australia\n",
      "JPN          Japan\n",
      "IN           India\n",
      "RU          Russia\n",
      "MOR        Morocco\n",
      "EG           Egypt\n",
      "           country drives_right\n",
      "US   United States         True\n",
      "AUS      Australia        False\n",
      "JPN          Japan        False\n",
      "IN           India        False\n",
      "RU          Russia         True\n",
      "MOR        Morocco         True\n",
      "EG           Egypt         True\n"
     ]
    }
   ],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('C:/Users/RBTG/OneDrive/Desktop/Data science/data/cars.txt', index_col = 0)\n",
    "\n",
    "# Print out country column as Pandas Series\n",
    "print(cars['country'])\n",
    "\n",
    "\n",
    "\n",
    "# Print out country column as Pandas DataFrame\n",
    "print(cars[['country']])\n",
    "\n",
    "\n",
    "# Print out DataFrame with country and drives_right columns\n",
    "print(cars[['country','drives_right']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='font-size:18px;'><span style=\"color:orange;\">Square brackets</span> can do more than just selecting columns. You can also use them to get rows, or observations, from a DataFrame. The following call selects the first five rows from the cars DataFrame:\n",
    "\n",
    "cars[0:5]\n",
    "The result is another DataFrame containing only the rows you specified.\n",
    "\n",
    "<span style=\"color:red\">Pay attention:</span> You can only select rows using square brackets if you specify a slice, like 0:4. Also, you're using the integer indexes of the rows here, not the row labels!</p>\n",
    "\n",
    "<li>Select the first 3 observations from cars and print them out.</li>\n",
    "<li>Select the fourth, fifth and sixth observation, corresponding to row indexes 3, 4 and 5, and print them out.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           country drives_right  cars_per_cap\n",
      "US   United States         True           809\n",
      "AUS      Australia        False           731\n",
      "JPN          Japan        False           588\n",
      "     country drives_right  cars_per_cap\n",
      "IN     India        False            18\n",
      "RU    Russia         True           200\n",
      "MOR  Morocco         True            70\n"
     ]
    }
   ],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('C:/Users/RBTG/OneDrive/Desktop/Data science/data/cars.txt', index_col = 0)\n",
    "\n",
    "# Print out first 3 observations\n",
    "print(cars[0:3])\n",
    "\n",
    "\n",
    "# Print out fourth, fifth and sixth observation\n",
    "print(cars[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='font-size:18px;'><span style=\"color:orange;\">loc and iloc</span> With loc and iloc you can do practically any data selection operation on DataFrames you can think of. loc is label-based, which means that you have to specify rows and columns based on their row and column labels. iloc is integer index based, so you have to specify rows and columns by their integer index like you did in the previous exercise.\n",
    "\n",
    "Try out the following commands in the IPython Shell to experiment with loc and iloc to select observations. Each pair of commands here gives the same result.\n",
    "\n",
    "cars.loc['RU'] <br>\n",
    "cars.iloc[4]<br>\n",
    "\n",
    "cars.loc[['RU']]<br>\n",
    "cars.iloc[[4]]<br>\n",
    "\n",
    "cars.loc[['RU', 'AUS']]<br>\n",
    "cars.iloc[[4, 1]]<br>\n",
    "As before, code is included that imports the cars data as a Pandas DataFrame.</p>\n",
    "\n",
    "<li>Use loc or iloc to select the observation corresponding to Japan as a Series. The label of this row is JPN, the index is 2. Make sure to print the resulting Series.\n",
    "</li>\n",
    "<li>Use loc or iloc to select the observations for Australia and Egypt as a DataFrame.</li> <br>You can find out about the labels/indexes of these rows by inspecting cars in the IPython Shell. Make sure to print the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country         Japan\n",
      "drives_right    False\n",
      "cars_per_cap      588\n",
      "Name: JPN, dtype: object\n",
      "country         Japan\n",
      "drives_right    False\n",
      "cars_per_cap      588\n",
      "Name: JPN, dtype: object\n",
      "       country drives_right  cars_per_cap\n",
      "AUS  Australia        False           731\n",
      "EG       Egypt         True            45\n",
      "       country drives_right  cars_per_cap\n",
      "AUS  Australia        False           731\n",
      "EG       Egypt         True            45\n"
     ]
    }
   ],
   "source": [
    "# Print out observation for Japan\n",
    "print(cars.loc['JPN'])\n",
    "print(cars.iloc[2])\n",
    "\n",
    "# Print out observations for Australia and Egypt\n",
    "print(cars.loc[['AUS','EG']])\n",
    "print(cars.iloc[[1,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style=\"color:orange;\">loc and iloc</span> also allow you to select both rows and columns from a DataFrame. To experiment, try out the following commands in the IPython Shell. Again, paired commands produce the same result.\n",
    "\n",
    "cars.loc['IN', 'cars_per_cap']<br>\n",
    "cars.iloc[3, 0]<br>\n",
    "\n",
    "cars.loc[['IN', 'RU'], 'cars_per_cap']<br>\n",
    "cars.iloc[[3, 4], 0]<br>\n",
    "\n",
    "cars.loc[['IN', 'RU'], ['cars_per_cap', 'country']]<br>\n",
    "cars.iloc[[3, 4], [0, 1]]<br>\n",
    "</p>\n",
    "<li>Print out the drives_right value of the row corresponding to Morocco (its row label is MOR)\n",
    "</li>\n",
    "<li>Print out a sub-DataFrame, containing the observations for Russia and Morocco and the columns country and drives_right.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    drives_right\n",
      "MOR         True\n",
      "\n",
      "     country drives_right\n",
      "RU    Russia         True\n",
      "MOR  Morocco         True\n"
     ]
    }
   ],
   "source": [
    "# Print out drives_right value of Morocco\n",
    "print(cars.loc[[\"MOR\"],['drives_right']])\n",
    "print()\n",
    "\n",
    "\n",
    "# Print sub-DataFrame\n",
    "print(cars.loc[[\"RU\",\"MOR\"],[\"country\",\"drives_right\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It's also possible to select only columns with <span style=\"color:orange;\">loc and iloc</span>. In both cases, you simply put a slice going from beginning to end in front of the comma:\n",
    "\n",
    "cars.loc[:, 'country']<br>\n",
    "cars.iloc[:, 1]<br>\n",
    "\n",
    "cars.loc[:, ['country','drives_right']]<br>\n",
    "cars.iloc[:, [1, 2]]<br>\n",
    "</p>\n",
    "<li>Print out the drives_right column as a Series using loc or iloc.<br></li>\n",
    "<li>Print out the drives_right column as a DataFrame using loc or iloc.<br></li>\n",
    "<li>Print out both the cars_per_cap and drives_right column as a DataFrame using loc or iloc.<br></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US      True\n",
      "AUS    False\n",
      "JPN    False\n",
      "IN     False\n",
      "RU      True\n",
      "MOR     True\n",
      "EG      True\n",
      "Name: drives_right, dtype: object\n",
      "\n",
      "    drives_right\n",
      "US          True\n",
      "AUS        False\n",
      "JPN        False\n",
      "IN         False\n",
      "RU          True\n",
      "MOR         True\n",
      "EG          True\n",
      "\n",
      "     cars_per_cap drives_right\n",
      "US            809         True\n",
      "AUS           731        False\n",
      "JPN           588        False\n",
      "IN             18        False\n",
      "RU            200         True\n",
      "MOR            70         True\n",
      "EG             45         True\n"
     ]
    }
   ],
   "source": [
    "# Print out drives_right column as Series\n",
    "print(cars.loc[:,'drives_right'])\n",
    "print()\n",
    "\n",
    "# Print out drives_right column as DataFrame\n",
    "print(cars.loc[:,['drives_right']])\n",
    "print()\n",
    "\n",
    "# Print out cars_per_cap and drives_right as DataFrame\n",
    "print(cars.loc[:,['cars_per_cap','drives_right']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Summary Statistics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Mean and Median</h3>\n",
    "Summary statistics are exactly what they sound like - they summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics. Calculating summary statistics allows you to get a better sense of your data, even if there's a lot of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv('C:/Users/RBTG/OneDrive/Desktop/Data science/data/sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Explore your new DataFrame first by printing the first few rows of the sales DataFrame.</li>\n",
    "<li>Print information about the columns in sales.</li>\n",
    "<li>Print the mean of the weekly_sales column.</li>\n",
    "<li>Print the median of the weekly_sales column.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store type  department      date  weekly_sales  is_holiday  temperature_c  \\\n",
      "0      1    A           1  2/5/2010      24924.50       False       5.727778   \n",
      "1      1    A           1  3/5/2010      21827.90       False       8.055556   \n",
      "2      1    A           1  4/2/2010      57258.43       False      16.816667   \n",
      "3      1    A           1  5/7/2010      17413.94       False      22.527778   \n",
      "4      1    A           1  6/4/2010      17558.09       False      27.050000   \n",
      "\n",
      "   fuel_price_usd_per_l  unemployment  \n",
      "0              0.679451         8.106  \n",
      "1              0.693452         8.106  \n",
      "2              0.718284         7.808  \n",
      "3              0.748928         7.808  \n",
      "4              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   store                 10774 non-null  int64  \n",
      " 1   type                  10774 non-null  object \n",
      " 2   department            10774 non-null  int64  \n",
      " 3   date                  10774 non-null  object \n",
      " 4   weekly_sales          10774 non-null  float64\n",
      " 5   is_holiday            10774 non-null  bool   \n",
      " 6   temperature_c         10774 non-null  float64\n",
      " 7   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 8   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(2), object(2)\n",
      "memory usage: 684.0+ KB\n",
      "None\n",
      "Mean of weekly_sales is  23843.95014850566\n",
      "Median of weekly_sales is  12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(\"Mean of weekly_sales is \",sales['weekly_sales'].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(\"Median of weekly_sales is \",sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Summarizing Dates</h3>\n",
    "Summary statistics can also be calculated on date columns that have values with the data type datetime64. Some summary statistics — like mean — don't make a ton of sense on dates, but others are super helpful, for example, minimum and maximum, which allow you to see what time range your data covers.\n",
    "\n",
    "<li>Print the maximum of the date column.</li>\n",
    "<li>Print the minimum of the date column.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9/2011\n",
      "1/13/2012\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales['date'].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Efficient summaries</h3>\n",
    "While pandas and NumPy have tons of functions, sometimes, you may need a different function to summarize your data.\n",
    "\n",
    "The .agg() method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. For example,\n",
    "\n",
    "df['column'].agg(function)\n",
    "\n",
    "<li>Use the custom iqr function defined for you along with .agg() to print the IQR of the temperature_c column of sales.</li>\n",
    "<li>Update the column selection to use the custom iqr function with .agg() to print the IQR of temperature_c, fuel_price_usd_per_l, and unemployment, in that order.</li>\n",
    "\n",
    "<li>Update the aggregation functions called by .agg(): include iqr and np.median in that order.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333337000003\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RBTG\\AppData\\Local\\Temp\\ipykernel_21840\\1446678071.py:7: FutureWarning: The provided callable <function median at 0x00000229FFD83100> is currently using Series.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median])\n",
      "C:\\Users\\RBTG\\AppData\\Local\\Temp\\ipykernel_21840\\1446678071.py:7: FutureWarning: The provided callable <function median at 0x00000229FFD83100> is currently using Series.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median])\n",
      "C:\\Users\\RBTG\\AppData\\Local\\Temp\\ipykernel_21840\\1446678071.py:7: FutureWarning: The provided callable <function median at 0x00000229FFD83100> is currently using Series.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>fuel_price_usd_per_l</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iqr</th>\n",
       "      <td>16.583333</td>\n",
       "      <td>0.073176</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>16.966667</td>\n",
       "      <td>0.743381</td>\n",
       "      <td>8.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature_c  fuel_price_usd_per_l  unemployment\n",
       "iqr         16.583333              0.073176         0.565\n",
       "median      16.966667              0.743381         8.099"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\">Cumulative statistics</h3>\n",
    "Cumulative statistics can also be helpful in tracking summary statistics over time. In this exercise, you'll calculate the cumulative sum and cumulative max of a department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far.\n",
    "\n",
    "A DataFrame called sales_1_1 has been created for you, which contains the sales data for department 1 of store 1. pandas is loaded as pd.\n",
    "\n",
    "<li>Sort the rows of sales_1_1 by the date column in ascending order.</li>\n",
    "<li>Get the cumulative sum of weekly_sales and add it as a new column of sales_1_1 called cum_weekly_sales.</li>\n",
    "<li>Get the cumulative maximum of weekly_sales, and add it as a column called cum_max_sales.</li>\n",
    "<li>Print the date, weekly_sales, cum_weekly_sales, and cum_max_sales columns.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "11   1/7/2011      15984.24          15984.24       15984.24\n",
      "8   10/1/2010      20094.19          36078.43       20094.19\n",
      "9   11/5/2010      34238.88          70317.31       34238.88\n",
      "10  12/3/2010      22517.56          92834.87       34238.88\n",
      "0    2/5/2010      24924.50         117759.37       34238.88\n",
      "1    3/5/2010      21827.90         139587.27       34238.88\n",
      "2    4/2/2010      57258.43         196845.70       57258.43\n",
      "3    5/7/2010      17413.94         214259.64       57258.43\n",
      "4    6/4/2010      17558.09         231817.73       57258.43\n",
      "5    7/2/2010      16333.14         248150.87       57258.43\n",
      "6    8/6/2010      17508.41         265659.28       57258.43\n",
      "7    9/3/2010      16241.78         281901.06       57258.43\n"
     ]
    }
   ],
   "source": [
    "sales_1_1 = sales[(sales['department']==1) & (sales['store']==1)]\n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values('date',ascending=True)\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
